{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n",
      "Nnet(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(18, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(30, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (6): Conv2d(35, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(40, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (11): Conv2d(45, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (12): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(50, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (16): Conv2d(55, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (17): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=240, out_features=500, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=500, out_features=201, bias=True)\n",
      "  )\n",
      ")\n",
      "len of label count 200\n",
      "label count [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 95, 207, 219, 143, 68, 285, 165, 172, 90, 274, 195, 111, 121, 131, 198, 118, 140, 125, 211, 180, 112, 129, 173, 133, 123, 198, 148, 182, 140, 134, 108, 113, 205, 80, 134, 103, 149, 186, 102, 95, 96, 188, 120, 97, 93, 126, 235, 107, 149, 195, 63, 221, 118, 221, 189, 240, 55, 144, 128, 169, 114, 147, 78, 163, 247, 54, 96, 96, 161, 230, 159, 179, 189, 235, 108, 130, 100, 205, 89, 274, 260, 91, 105, 61, 216, 148, 182, 103, 145, 139, 215, 198, 234, 64, 163, 105, 77, 82, 204, 62]\n",
      "epoch: 0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/split_Ori_Face/train/SandraDayOConnor/239.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c7ac7e0331be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# Get the next minibatch of images, labels for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mminibatch_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0;31m#print(\"mini_batch\", minibatch_count)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;31m#print('labels', len(labels))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c7ac7e0331be>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2770\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2771\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/split_Ori_Face/train/SandraDayOConnor/239.jpg'"
     ]
    }
   ],
   "source": [
    "# your code below for training\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.nn.init as torch_init\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class loader(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.frame.iloc[idx, 0])\n",
    "        img = Image.open(img_name)\n",
    "        label = self.frame.iloc[idx, 1]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "    \n",
    "class Nnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Nnet, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 18, 3, stride=1, padding=1, bias=False), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(18, 30 , 3, stride=1, padding=1, bias=False), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.Conv2d(30, 35, 3,stride=1, padding=1, bias=False),\n",
    "            nn.Conv2d(35, 40, 3,stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.Conv2d(40, 45, 3, stride=1, padding=1, bias=False),\n",
    "            nn.Conv2d(45, 50, 3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU( inplace=True),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.Conv2d(50, 55, 3, stride=1, padding=1, bias=False),\n",
    "            nn.Conv2d(55, 60, 3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU( inplace=True),\n",
    "            nn.MaxPool2d(3),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(240,500), # 240, 500\n",
    "            nn.ReLU( inplace=True),\n",
    "            nn.Linear(500,500), # 500, 500\n",
    "            nn.ReLU( inplace=True),\n",
    "            nn.Linear(500,500), # 500, 500\n",
    "            nn.ReLU( inplace=True),\n",
    "            nn.Linear(500, 201), # 500, 201\n",
    "            #nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def num_flat_features(self, inputs):\n",
    "        \n",
    "        # Get the dimensions of the layers excluding the inputs\n",
    "        size = inputs.size()[1:]\n",
    "        # Track the number of features\n",
    "        num_features = 1\n",
    "        \n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        \n",
    "        return num_features\n",
    "\n",
    "    def forward(self, input):\n",
    "        x=self.main(input)\n",
    "        #print('num:', self.num_flat_features(x))\n",
    "        x=x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "        return self.fc(x)\n",
    "\n",
    "        \n",
    "#from david_cnn import *\n",
    "os.environ['XDG_CACHE_HOME']='/tmp/xdg-cache'\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")\n",
    "\n",
    "net=Nnet().to(computing_device)\n",
    "net.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(net)\n",
    "\n",
    "#loss criteria are defined in the torch.nn package\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Instantiate the gradient descent optimizer - use Adam optimizer with default parameters\n",
    "optimizer = optim.Adam(net.parameters(),lr = 0.001)\n",
    "\n",
    "# Save states of a new net\n",
    "init_state = copy.deepcopy(net.state_dict())\n",
    "init_state_opt = copy.deepcopy(optimizer.state_dict())\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor()])\n",
    "dataset = loader('train.csv', '/content/', transform=transform)\n",
    "batch_size = 64\n",
    "#validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 1738\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "# Addressing data label imbalance issue through resampling \n",
    "dataframe = dataset.frame\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X = dataset.frame['path'] # Path names (X)\n",
    "y = dataset.frame['label'] # Labels (y)\n",
    "#print(dataframe.head())\n",
    "\n",
    "\n",
    "\n",
    "# Iterating over K-folds\n",
    "kfold = 1\n",
    "folds_acc = []\n",
    "models = []\n",
    "optims = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "early_stop_num = 5\n",
    "skf = KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "\n",
    "for train_index, test_index in skf.split(X):\n",
    "    best_model = None\n",
    "    best_optim = None\n",
    "\n",
    "    #print('kfold:', kfold)\n",
    "    # Loading a new net for training\n",
    "    net.load_state_dict(init_state)\n",
    "    optimizer.load_state_dict(init_state_opt)\n",
    "    #print(len(train_index), len(test_index))\n",
    "    #print('train_index:', train_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #print('x_train len', len(X_train))\n",
    "    #print('x_train vals', X_train[:5])\n",
    "    class_labels_count = [0]*200\n",
    "    #class_labels_count = np.array([len(np.where(y_train==t)[0]) for t in np.unique(y_train)])\n",
    "    for t in range(len(class_labels_count)):\n",
    "        if t in np.unique(y_train):\n",
    "          class_labels_count[t] = len(np.where(y_train==t)[0])\n",
    "    #class_labels_count = [len(np.where(y_train==t)) if t in np.unique(y_train) else x for x in class_labels_count]\n",
    "    print('len of label count', len(class_labels_count))\n",
    "    print('label count', class_labels_count)\n",
    "\n",
    "    weights = [0]*201\n",
    "    for i in range(len(class_labels_count)):   \n",
    "        if (class_labels_count[i] != 0):\n",
    "          weights[i+1] = 1. / class_labels_count[i]\n",
    "    #print('weights', weights)\n",
    "    #print(len(weights))\n",
    "    #print(len(y_train))\n",
    "    \n",
    "    sample_weights = np.array([weights[t] for t in y_train])\n",
    "\n",
    "    #dataset_size = len(dataset)\n",
    "    #indices = list(range(dataset_size))\n",
    "    #split = int(np.floor(validation_split * dataset_size))\n",
    "    #train_indices, val_indices = indices[split:], indices[:split]\n",
    "    #print('val_in:', len(val_indices))\n",
    "    val_indices = test_index\n",
    "\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    #train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    train_sampler = WeightedRandomSampler(sample_weights, replacement=True, num_samples=len(sample_weights))\n",
    "    #valid_sampler = WeightedRandomSampler(sample_weights, replacement=True, num_samples=len(sample_weights))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                               sampler=train_sampler)\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "\n",
    "    # Track the loss across training\n",
    "    total_loss = []\n",
    "    t_loss = []\n",
    "    v_loss = []\n",
    "    avg_minibatch_loss = []\n",
    "    N = 50\n",
    "\n",
    "    for epoch in range(15):\n",
    "        print('epoch:', epoch)\n",
    "        N_minibatch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        best_accuracy = 0\n",
    "        best_error = np.inf\n",
    "        lossVT = 0\n",
    "\n",
    "        # Get the next minibatch of images, labels for training\n",
    "        for minibatch_count, (images, labels) in enumerate(train_loader, 0):\n",
    "            #print(\"mini_batch\", minibatch_count)\n",
    "            #print('labels', len(labels))\n",
    "            # Zero out the stored gradient (buffer) from the previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "            images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "            # Perform the forward pass through the network and compute the loss\n",
    "            outputs = net(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Automagically compute the gradients and backpropagate the loss through the network\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()    \n",
    "            # Add this iteration's loss to the total_loss\n",
    "            total_loss.append(loss.item())\n",
    "            N_minibatch_loss += loss\n",
    "\n",
    "\n",
    "            if minibatch_count % N == 49:\n",
    "                #Print the loss averaged over the last N mini-batches\n",
    "                N_minibatch_loss /= N\n",
    "                print('Epoch %d, average minibatch %d loss: %.3f' % (epoch + 1, minibatch_count+1, N_minibatch_loss))\n",
    "                # Add the averaged loss over N minibatches and reset the counter\n",
    "                avg_minibatch_loss.append(N_minibatch_loss)\n",
    "                N_minibatch_loss = 0.0\n",
    "            \n",
    "        \n",
    "        print(\"Finished\", epoch + 1, \"epochs of training\")\n",
    "        \n",
    "        # Implement validation #with torch.no_grad():\n",
    "        with torch.no_grad():\n",
    "            for minibatch_count, (images, labels) in enumerate(validation_loader, 0):\n",
    "                # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "                images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "                #print(len(labels))\n",
    "                outputsV = net(images)\n",
    "\n",
    "                for index in range(len(labels)):    \n",
    "                    real_y = labels[index]\n",
    "                    #print('real_y', real_y.item())\n",
    "                    out = net(images[index].view(-1,3,224,224))\n",
    "                    #print('out:', out)\n",
    "                    pred_y = torch.argmax(out)\n",
    "                    #print('pred_y', pred_y.item())\n",
    "\n",
    "                    if (real_y.item() == pred_y.item()):\n",
    "                        correct += 1\n",
    "                    total += 1\n",
    "        accuracy = correct/total\n",
    "        val_error = 1 - accuracy\n",
    "        \n",
    "        # Early stop checking\n",
    "        if val_error >= best_error:\n",
    "            es_count += 1\n",
    "            if es_count == early_stop_num:\n",
    "                print('breaking')\n",
    "                break\n",
    "        else:\n",
    "            best_error = val_error\n",
    "            best_accuracy = accuracy\n",
    "            best_model = copy.deepcopy(net.state_dict())\n",
    "            best_optim = copy.deepcopy(optimizer.state_dict())\n",
    "          \n",
    "        \n",
    "        t_loss.append(np.mean(total_loss))\n",
    "        v_loss.append(val_error) \n",
    "        print('Iteration accuracy: %.3f' % ((accuracy)*100))\n",
    "        print('Val Error: %.3f' %((val_error)*100))\n",
    "    \n",
    "    # Best model for kth fold\n",
    "    models.append(best_model)\n",
    "    optims.append(best_optim)\n",
    "    print('Best accuracy: %.3f' % ((best_accuracy)*100))\n",
    "    folds_acc.append(best_accuracy)\n",
    "    kfold += 1\n",
    "\n",
    "# Getting best model\n",
    "best_idx = np.argmax(folds_acc)\n",
    "best_model = models[best_idx]\n",
    "best_optim = optims[best_idx]\n",
    "# Loading\n",
    "net.load_state_dict(best_model)\n",
    "optimizer.load_state_dict(best_optim)\n",
    "\n",
    "# Using whole dataset as test set\n",
    "transform = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor()])\n",
    "testset = loader('test.csv','/content/',transform=transform)\n",
    "testset_size = len(testset)\n",
    "indices = list(range(testset_size))\n",
    "#split = int(np.floor(validation_split * dataset_size))\n",
    "#train_indices, val_indices = indices[split:], indices[:split]\n",
    "valid_sampler = SubsetRandomSampler(indices)\n",
    "validation_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "\n",
    "y_vals = []\n",
    "y_preds = []\n",
    "with torch.no_grad():\n",
    "    for minibatch_count, (images, labels) in enumerate(validation_loader, 0):\n",
    "        # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "        images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "        for index in range(len(labels)):    \n",
    "            real_y = labels[index]\n",
    "            y_vals.append(real_y.item())\n",
    "            #print('real_y', real_y.item())\n",
    "            out = net(images[index].view(-1,3,224,224))\n",
    "            #print('out:', out)\n",
    "            pred_y = torch.argmax(out)\n",
    "            y_preds.append(pred_y.item())\n",
    "            #print('pred_y', pred_y.item())\n",
    "\n",
    "            if (real_y.item() == pred_y.item()):\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    accuracy = correct/total\n",
    "\n",
    "report = classification_report(y_vals, y_preds, labels=range(201), output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_vals, y_preds, labels=range(201))\n",
    "\n",
    "class_acc = []\n",
    "best = []\n",
    "worst = []\n",
    "\n",
    "# Getting accuracies for each label class\n",
    "for k, v in report.items():\n",
    "  if(isinstance(int(k), int)):\n",
    "    if(int(k) == 0):\n",
    "      acc = 0\n",
    "    else:\n",
    "      tp = conf_matrix[int(k)][int(k)]\n",
    "      num = v.get('support')\n",
    "      acc = tp/num\n",
    "      class_acc.append(acc)\n",
    "      if(k=='200'):\n",
    "        break\n",
    "\n",
    "# Getting top 5 and bottom 5 labels\n",
    "for i in range(5):\n",
    "  maxA = np.argmax(class_acc)\n",
    "  minA = np.argmin(class_acc)\n",
    "\n",
    "  max_precision = report.get(str(maxA)).get('precision')\n",
    "  max_recall = report.get(str(maxA)).get('recall')\n",
    "  max_bcr = (max_precision + max_recall)/2\n",
    "\n",
    "  min_precision = report.get(str(minA)).get('precision')\n",
    "  min_recall = report.get(str(minA)).get('recall')\n",
    "  min_bcr = (min_precision + min_recall)/2\n",
    "\n",
    "  # appending by label, acc, precision, recall, \n",
    "  best.append((maxA, class_acc[maxA], max_precision, max_recall, max_bcr))\n",
    "  worst.append((minA, class_acc[minA], min_precision, min_recall, min_bcr))\n",
    "  class_acc.pop(maxA)\n",
    "  class_acc.pop(minA)\n",
    "print(best)\n",
    "print(worst)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
