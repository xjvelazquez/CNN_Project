{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to read csv file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://drive.google.com/open?id=1Q8KUlytiQ2UDI6qb0YML8vASLDAijDg2'\n",
    "_, id = link.split('=')\n",
    "print (id) # Verify that you have everything after '='\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "print(downloaded)\n",
    "downloaded.GetContentFile('split_ori_face.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls\n",
    "# !unzip split_ori_face.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip split_ori_face.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights_for_balanced_classes(images, nclasses):                        \n",
    "    count = [0] * nclasses                                                      \n",
    "    for item in images:                                                         \n",
    "        count[item] += 1                                                     \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))                                                   \n",
    "    for i in range(nclasses):   \n",
    "        if count[i] != 0:\n",
    "          weight_per_class[i] = N/float(count[i])                                 \n",
    "    weight = [0] * len(images)                                              \n",
    "    for idx, val in enumerate(images):                                          \n",
    "        weight[idx] = weight_per_class[val]                                  \n",
    "    return weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.nn.init as torch_init\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class loader(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.frame.iloc[idx, 0])\n",
    "        img = Image.open(img_name)\n",
    "        label = self.frame.iloc[idx, 1]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "    \n",
    "class Nnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Nnet, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 21 , 3, stride=2, padding=1, bias=False), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(21, 20, 3,stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(20, 15, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU( inplace=True),\n",
    "            nn.Conv2d(15, 7, 5, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU( inplace=True),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1183,500),\n",
    "            nn.ReLU( inplace=True),\n",
    "            nn.Linear(500, 201),\n",
    "            #nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def num_flat_features(self, inputs):\n",
    "        \n",
    "        # Get the dimensions of the layers excluding the inputs\n",
    "        size = inputs.size()[1:]\n",
    "        # Track the number of features\n",
    "        num_features = 1\n",
    "        \n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        \n",
    "        return num_features\n",
    "\n",
    "    def forward(self, input):\n",
    "        x=self.main(input)\n",
    "        #print('yo:', self.num_flat_features(x))\n",
    "        x=x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "        return self.fc(x)\n",
    "\n",
    "        \n",
    "os.environ['XDG_CACHE_HOME']='/tmp/xdg-cache'\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")\n",
    "\n",
    "net=Nnet().to(computing_device)\n",
    "net.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(net)\n",
    "\n",
    "#loss criteria are defined in the torch.nn package\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "#Instantiate the gradient descent optimizer - use Adam optimizer with default parameters\n",
    "optimizer = optim.Adam(net.parameters(),lr = 0.001)\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor()])\n",
    "dataset = loader('train.csv','/content/',transform=transform)\n",
    "batch_size = 64\n",
    "validation_split = .33\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n",
    "\n",
    "# Track the loss across training\n",
    "total_loss = []\n",
    "t_loss = []\n",
    "t_acc = []\n",
    "v_loss = []\n",
    "models = []\n",
    "optims = []\n",
    "folds_acc = []\n",
    "best_error = np.inf\n",
    "best_accuracy = 0\n",
    "avg_minibatch_loss = []\n",
    "N = 50\n",
    "early_stop_num = 5\n",
    "es_count = 0\n",
    "\n",
    "for epoch in range(20):\n",
    "    N_minibatch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "\n",
    "    # Get the next minibatch of images, labels for training\n",
    "    for minibatch_count, (images, labels) in enumerate(train_loader, 0):\n",
    "        #print(\"mini_batch\", minibatch_count)\n",
    "        # Zero out the stored gradient (buffer) from the previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "        images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "        # Perform the forward pass through the network and compute the loss\n",
    "        outputs = net(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        # Automagically compute the gradients and backpropagate the loss through the network\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()    \n",
    "        # Add this iteration's loss to the total_loss\n",
    "        total_loss.append(loss.item())\n",
    "        N_minibatch_loss += loss\n",
    "               \n",
    "        \n",
    "        if minibatch_count % N == 49:\n",
    "            #Print the loss averaged over the last N mini-batches\n",
    "            N_minibatch_loss /= N\n",
    "            print('Epoch %d, average minibatch %d loss: %.3f' % (epoch + 1, minibatch_count+1, N_minibatch_loss))\n",
    "            # Add the averaged loss over N minibatches and reset the counter\n",
    "            avg_minibatch_loss.append(N_minibatch_loss)\n",
    "            N_minibatch_loss = 0.0\n",
    "\n",
    "    print(\"Finished\", epoch + 1, \"epochs of training\")\n",
    "    # TODO: Implement validation #with torch.no_grad():\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for minibatch_count, (images, labels) in enumerate(validation_loader, 0):\n",
    "            # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "            images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "            for index in range(len(labels)):    \n",
    "                real_y = labels[index]\n",
    "                #print('real_y', real_y)\n",
    "                out = net(images[index].view(-1,3,224,224))\n",
    "                #print('out:', out)\n",
    "                pred_y = torch.argmax(out)\n",
    "                #print('pred_y', pred_y)\n",
    "\n",
    "                if (real_y.item() == pred_y.item()):\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "    accuracy = correct/total\n",
    "    val_error = 1-accuracy\n",
    "        \n",
    "    # Early stop checking\n",
    "    if val_error >= best_error:\n",
    "        es_count += 1\n",
    "        if es_count == early_stop_num:\n",
    "            print('breaking')\n",
    "            break\n",
    "    else:\n",
    "        es_count = 0 \n",
    "        best_error = val_error\n",
    "        best_accuracy = accuracy\n",
    "        best_model = copy.deepcopy(net.state_dict())\n",
    "        best_optim = copy.deepcopy(optimizer.state_dict())\n",
    "          \n",
    "        \n",
    "    t_loss.append(np.mean(total_loss))\n",
    "    t_acc.append(100-(np.mean(total_loss)))\n",
    "    v_loss.append(val_error) \n",
    "    print('Iteration accuracy: %.3f' % ((accuracy)*100))\n",
    "    print('Val Error: %.3f' %((val_error)*100))\n",
    "    \n",
    "# Best model for kth fold\n",
    "models.append(best_model)\n",
    "optims.append(best_optim)\n",
    "print('Best accuracy: %.3f' % ((best_accuracy)*100))\n",
    "folds_acc.append(best_accuracy)\n",
    "#kfold += 1\n",
    "\n",
    "# Getting best model\n",
    "best_idx = np.argmax(folds_acc)\n",
    "best_model = models[best_idx]\n",
    "best_optim = optims[best_idx]\n",
    "# Loading\n",
    "net.load_state_dict(best_model)\n",
    "optimizer.load_state_dict(best_optim)\n",
    "\n",
    "# Using whole dataset as test set\n",
    "transform = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor()])\n",
    "testset = loader('test.csv','/content/',transform=transform)\n",
    "testset_size = len(testset)\n",
    "indices = list(range(testset_size))\n",
    "#split = int(np.floor(validation_split * dataset_size))\n",
    "#train_indices, val_indices = indices[split:], indices[:split]\n",
    "valid_sampler = SubsetRandomSampler(indices)\n",
    "validation_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "\n",
    "y_vals = []\n",
    "y_preds = []\n",
    "with torch.no_grad():\n",
    "    for minibatch_count, (images, labels) in enumerate(validation_loader, 0):\n",
    "        # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "        images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "        for index in range(len(labels)):    \n",
    "            real_y = labels[index]\n",
    "            y_vals.append(real_y.item())\n",
    "            #print('real_y', real_y.item())\n",
    "            out = net(images[index].view(-1,3,224,224))\n",
    "            #print('out:', out)\n",
    "            pred_y = torch.argmax(out)\n",
    "            y_preds.append(pred_y.item())\n",
    "            #print('pred_y', pred_y.item())\n",
    "\n",
    "            if (real_y.item() == pred_y.item()):\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    accuracy = correct/total\n",
    "\n",
    "print('tloss', t_loss)\n",
    "print('t_acc', t_acc)\n",
    "print('vloss:', v_loss)\n",
    "print('v_acc:', folds_acc)\n",
    "report = classification_report(y_vals, y_preds, labels=range(201), output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_vals, y_preds, labels=range(201))\n",
    "\n",
    "class_acc = []\n",
    "best = []\n",
    "worst = []\n",
    "\n",
    "# Getting accuracies for each label class\n",
    "for k, v in report.items():\n",
    "  if(isinstance(int(k), int)):\n",
    "    if(int(k) == 0):\n",
    "      acc = 0\n",
    "    else:\n",
    "      tp = conf_matrix[int(k)][int(k)]\n",
    "      num = v.get('support')\n",
    "      acc = tp/num\n",
    "      class_acc.append(acc)\n",
    "      if(k=='200'):\n",
    "        break\n",
    "\n",
    "# Getting top 5 and bottom 5 labels\n",
    "# appending by label, acc, precision, recall, \n",
    "for i in range(5):\n",
    "  maxA = np.argmax(class_acc)\n",
    "  max_precision = report.get(str(maxA)).get('precision')\n",
    "  max_recall = report.get(str(maxA)).get('recall')\n",
    "  max_bcr = (max_precision + max_recall)/2\n",
    "  best.append((maxA, class_acc[maxA], max_precision, max_recall, max_bcr))\n",
    "  class_acc.pop(maxA)\n",
    "\n",
    "\n",
    "  minA = np.argmin(class_acc)\n",
    "  min_precision = report.get(str(minA)).get('precision')\n",
    "  min_recall = report.get(str(minA)).get('recall')\n",
    "  min_bcr = (min_precision + min_recall)/2\n",
    "  worst.append((minA, class_acc[minA], min_precision, min_recall, min_bcr))\n",
    "  class_acc.pop(minA)\n",
    "print('best:', best)\n",
    "print('worst:', worst)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), '/content/basemodel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), '/content/basemodel.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
